{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0ee20b-df97-4753-894a-fe0fdd54e414",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data exploration\n",
    "In this notebook we will analyse the revisions data that has been indexed in the MongoDB instance. This index process was carried out with the programs from the 'scripts' folder. We will create datasets with general information and statistics from this data that will be used to both understand the edits behaviours in Wikidata and also to create predictive models from these datasets later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3601615-18d5-44a8-b56b-13d0f1daa151",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "We will start by preparing the notebook. The following cells must be executed if there is a problem saving the figures that are created in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c728304-bd6b-4086-acca-08c7d8f5f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29241a67-2bc5-4e71-baad-60dd618301cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter lab build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54677c03-9a22-480b-860c-8338dc73b9b8",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Now we will import the general modules used accross the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebab51-1787-4396-93ef-252949f0648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a78dc2-2977-4129-bc1c-5d515d7f3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "op_types = ['add', 'remove', 'replace']\n",
    "op_colors = {'add': px.colors.qualitative.Plotly[0], 'remove': px.colors.qualitative.Plotly[1], 'replace': px.colors.qualitative.Plotly[2]}\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79579be8-2df6-47b9-a9be-2770dabea042",
   "metadata": {},
   "source": [
    "### Constants\n",
    "These will be the constants that are reused throughout the notebook. They mainly consist of directories where data will be read from or written into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8faf8ff-5531-460e-be27-90274a73de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('..', 'data')\n",
    "\n",
    "NOTEBOOK1_OUTPUT_DIR = os.path.join('output', '1_data_fetching')\n",
    "CLASSES_FILE = os.path.join(NOTEBOOK1_OUTPUT_DIR, 'top_classes.pkl')\n",
    "\n",
    "OUTPUT_DIR = os.path.join('output', '2_data_exploration')\n",
    "CHARTS_OUTPUT_DIR = os.path.join(OUTPUT_DIR, 'charts')\n",
    "CSV_OUTPUT_DIR = os.path.join(OUTPUT_DIR, 'csv')\n",
    "DATAFRAMES_OUTPUT_DIR = os.path.join(OUTPUT_DIR, 'df_results')\n",
    "\n",
    "WIKIDATA_BASE = \"https://www.wikidata.org/w/api.php\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4a34a-1558-4c66-89b1-93f4514b29d5",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "To finalize the setup of this notebook, we will define a set of common functions. The first set of functions will be used to fetch labels of property ids from Wikidata. The second set will be used to serialize and deserialize data with pickle: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b3020-28bc-4521-96f7-56eb4508b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "props_name_cache = {}\n",
    "\n",
    "\n",
    "def update_props_name_cache(props_pids):\n",
    "    props = '|'.join(props_pids)\n",
    "    url = f'{WIKIDATA_BASE}?action=wbgetentities&format=json&props=labels&ids={props}&languages=en'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    for k, v in data['entities'].items():\n",
    "        if 'missing' in v:\n",
    "            props_name_cache[k] = f\"[deleted property] ({v['id']})\"\n",
    "        else:\n",
    "            try:\n",
    "                props_name_cache[k] = v['labels']['en']['value']\n",
    "            except KeyError:\n",
    "                props_name_cache[k] = f\"[No english label] ({v['id']})\"\n",
    "\n",
    "def get_name_of_props(props_pids):\n",
    "    props_to_query = [p for p in props_pids if p not in props_name_cache]\n",
    "    if len(props_to_query) > 0:\n",
    "        update_props_name_cache(props_to_query)\n",
    "    return [props_name_cache[p] for p in props_pids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fe250-0146-41d8-8532-7d6cbe6979e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    with open(os.path.join(DATAFRAMES_OUTPUT_DIR, f\"{filename}.pkl\"), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_df(df, filename):\n",
    "    with open(os.path.join(DATAFRAMES_OUTPUT_DIR, f\"{filename}.pkl\"), 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "def save_csv(df, filename):\n",
    "    with open(os.path.join(CSV_OUTPUT_DIR, f\"{filename}.csv\"), 'w') as f:\n",
    "        df.to_csv(f, index=False)\n",
    "\n",
    "def save_fig(fig, filename):\n",
    "    fig.write_html(os.path.join(CHARTS_OUTPUT_DIR, f\"{filename}.html\"), include_plotlyjs=False)\n",
    "    fig.write_image(os.path.join(CHARTS_OUTPUT_DIR, f\"{filename}.svg\"))\n",
    "    fig.write_image(os.path.join(CHARTS_OUTPUT_DIR, f\"{filename}.pdf\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7eaad-1b71-44ba-98e4-8ac0b731ad1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the data from the previous notebook\n",
    "To begin with this notebook we are going to load the classes that compose our dataset, which were serialized in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389891f-788d-4dbb-ae9f-90f975c7b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class KGEntity:\n",
    "    qid: str\n",
    "    pagerank_score: float\n",
    "\n",
    "@dataclass\n",
    "class KGClass:\n",
    "    name: str\n",
    "    qid: str\n",
    "    classrank_score: float\n",
    "    instances: List[KGEntity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249d31e-f5e2-454a-9cfc-995e780c41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLASSES_FILE, 'rb') as f:\n",
    "    top_classes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c2828-dc22-452b-b3f9-5cf99bbaf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([len(c.instances) for c in top_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbfcf9-6504-4186-a257-486e3658fcc7",
   "metadata": {},
   "source": [
    "We can see how our dataset is composed of 9693840 entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63241c17-1b3f-47d8-9aeb-4d8d14ca7ee0",
   "metadata": {},
   "source": [
    "## Displaying general information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ceaeac-d738-49e1-887d-c4ff16438e6f",
   "metadata": {},
   "source": [
    "We are going to perform now a quick exploratory analysis to confirm that the data has been loaded correctly. After executing the next cell we can see which are the top 25 classes of our dataset based on their classrank score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9be73-3b79-46f0-9a45-4f962c92d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 25 classes based on classrank\")\n",
    "print(\"-\" * 35)\n",
    "print('\\n'.join([f\"{c.name} - score: {c.classrank_score}\" for c in top_classes[:25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717986e-51bd-4e24-9348-6c1fed787a3d",
   "metadata": {},
   "source": [
    "We are now going to plot the distribution of instances accross each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deec1c7-aaf3-47f4-8eb9-b55aed08f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "x = [len(c.instances) for c in top_classes]\n",
    "labels = {\n",
    "    \"x\": \"Number of class instances\"\n",
    "}\n",
    "\n",
    "fig = px.histogram(x=x, template='plotly_white', labels=labels)\n",
    "fig.update_layout(bargap=0.02)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc8697-5685-4626-a5f6-073e9967214a",
   "metadata": {},
   "source": [
    "We can see from the figure above that the mayority of classes have less than 200K instances, while there are some isolated classes with more instances, with a class having 3.8 millions of instances. We will finish this initial exploration saving the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7970aca-97ad-45ec-af14-2b5918594470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_fig(fig, '0_histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd9875-8785-45d2-af07-a9360f5afab4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Querying the diff data\n",
    "We are now going to query the revision data that has been indexed to the database. Our database will contain the following two collections:\n",
    "- __wd_entities__: This collection contains the current entity data of our dataset. It represents the data model of Wikidata, with each entity having the following schema:\n",
    "    - id: Internal Wikidata identificator of the entity (e.g. 2491849209).\n",
    "    - entity_id: 'Public' id of the entity (e.g. Q42).\n",
    "    - class_ids: List of ids of the classes the entity belongs to (e.g. \\[Q5, Q20\\]).\n",
    "    - entity_json: Complete JSON content of the entity in Wikidata (see [this link](https://doc.wikimedia.org/Wikibase/master/php/md_docs_topics_json.html) for more information about the JSON schema followed).\n",
    "- __wd_revisions__: This collection contains information about all the revisions made to each entity from the dataset. It follows this schema:\n",
    "    - id: Internal Wikidata identificator of the revision (e.g. 129529015819).\n",
    "    - entity_id: 'Public' id of the entity this revision refers tol (e.g. Q42).\n",
    "    - class_ids: List of ids of the classes the entity belongs to (e.g. \\[Q5, Q20\\]).\n",
    "    - parent_id: Internal Wikidata identificator of the previous revision made to the entity (e.g. 31980681969).\n",
    "    - timestamp: Timestamp of the revision, following the 'YYYY-MM-DDThh:mm:ssZ' format (e.g. 2014-08-28T15:45:20Z).\n",
    "    - username: Username of the user that made the revision (e.g. 'Axipbot').\n",
    "    - comment: Comment of the user that made the revision, if any.\n",
    "    - entity_diff: List of operations made to the Wikidata entity in the revision, following the [JSON Patch](http://jsonpatch.com) format.\n",
    "\n",
    "An example value of the entity diff array can be seen here:\n",
    "```json\n",
    "{\n",
    "    \"op\": \"replace\",\n",
    "    \"path\": \"/claims/P150/7/mainsnak/datavalue/value/numeric-id\",\n",
    "    \"value\": 31326\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8b66c-73c2-4cf9-bf61-f132560625bc",
   "metadata": {},
   "source": [
    "### Connecting to the database\n",
    "We will now make a connection to the Mongo database where this data is stored. If everything was set up from the docker-compose file, this connection will be configured automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f2ae7-d83b-4d31-8e32-bca9288dc7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "\n",
    "def env_or_callback(env_name, callback, *args):\n",
    "    return os.getenv(env_name) if os.getenv(env_name) is not None else callback(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a8022-a691-4895-90fe-60d20ae545aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "\n",
    "MONGO_USERNAME = env_or_callback(\"MONGO_USERNAME\", input, \"Mongo username: \")\n",
    "MONGO_PASSWORD = env_or_callback(\"MONGO_PASSWORD\", getpass.getpass, \"Mongo password: \")\n",
    "MONGO_URL = env_or_callback(\"MONGO_URL\", input, \"Mongo url: \")\n",
    "MONGO_DATABASE = \"wd_diff\"\n",
    "\n",
    "def get_database():\n",
    "    # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "    CONNECTION_STRING = f\"mongodb://{MONGO_USERNAME}:{MONGO_PASSWORD}@127.0.0.1:27017/{MONGO_DATABASE}\"\n",
    "\n",
    "    # Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
    "    client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "    # Create the database for our example (we will use the same database throughout the tutorial\n",
    "    return client[MONGO_DATABASE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b95858-39b1-460c-9eca-c828cd314c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_database()\n",
    "wd_entities = db.wd_entities\n",
    "wd_revisions = db.wd_revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d9797-efd5-46ea-bf9e-ebc57a5efb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indexes creation\n",
    "Before querying the data we are going to create indexes that support our queries to speed up their execution. We will be mainly querying information based on their entity id or their class id, so we will be making indexes on those fields. This step may take a while depending on the i/o speed of the disk where Mongo data is stored.\n",
    "\n",
    "If the indexes where already created, this cell will not modify anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962731c5-a5ef-4e4a-ae5c-07290a7ebeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_revisions.create_index([(\"class_ids\", pymongo.DESCENDING)])\n",
    "wd_revisions.create_index([(\"entity_id\", pymongo.DESCENDING)])\n",
    "wd_entities.create_index([(\"class_ids\", pymongo.DESCENDING)])\n",
    "wd_entities.create_index([(\"entity_id\", pymongo.DESCENDING)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf906ff-ae18-41a2-9859-ec8ddf581945",
   "metadata": {},
   "source": [
    "We will now list the indexes of both collections to check if they have been created correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083c7a5-588a-4508-9f0d-ca381270c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(wd_entities.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b04df-5e2e-4f0a-a109-5164f275a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(wd_revisions.list_indexes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35505a5-05ac-412d-907e-6b8b6da55fa9",
   "metadata": {},
   "source": [
    "### A. Descriptive analysis\n",
    "With our connection to the database ready we can start exploring the data. The steps of each analysis will always be very similar:\n",
    "1. Define a set of functions used to query the information we need.\n",
    "2. Execute the queries and store the information in a Dataframe.\n",
    "3. Briefly explore and describe the Dataframe.\n",
    "4. Visualize the contents of the Dataframe.\n",
    "\n",
    "Since in most cases the **step number 2 may take a long time to execute, we provide the precomputed results** to avoid these execution times and continue the execution of the notebook. These precomputed results are usually provided in the cell following to the long computation one.\n",
    "\n",
    "To begin we will perform a descriptive analysis of the *operations* that compose our dataset. It is important to first mention the differences between *operation* and *revision* in our context. A revision is analogous to the one in Wikidata, where a user modifies the contents of an entity. One revision can be composed of many *operations* which can be seen as atomic changes to an entity. An operation could belong to one of three different types: 'add', 'remove' or 'replace'.\n",
    "\n",
    "The following cell defines two functions that return the number of operations of instances of a class in our data. The first one aggregates all the operations, while the second one performs the aggregation based on each operation type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117aaf6c-4924-43ba-890e-4100d32ac3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_operations_per_instance(collection, class_id):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"class_ids\": class_id}},\n",
    "        {\"$unwind\": \"$entity_diff\"},\n",
    "        {\n",
    "            \"$group\":\n",
    "            {\n",
    "                \"_id\": \"$entity_id\",\n",
    "                \"count\": {\"$sum\": 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))\n",
    "\n",
    "def get_number_of_op_types_per_instance(collection, class_id):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"class_ids\": class_id}},\n",
    "        {\"$unwind\": \"$entity_diff\"},\n",
    "        {\n",
    "            \"$group\":\n",
    "            {\n",
    "                \"_id\": {\"entity\": \"$entity_id\", \"op\": \"$entity_diff.op\"},\n",
    "                \"count\": {\"$sum\": 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd73ad-d0f3-471b-a300-b350e5ad40b8",
   "metadata": {},
   "source": [
    "With the functions ready we will now create our first Dataframe with statistics about the operations of each class.\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 2h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d00da3-176e-46b0-b6c3-68be8f658464",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'class': [],\n",
    "    'op': [],\n",
    "    'mean': [],\n",
    "    'median': [],\n",
    "    'std': [],\n",
    "    'max': [],\n",
    "    'min': []\n",
    "}\n",
    "\n",
    "ops = ['add', 'remove', 'replace']\n",
    "\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        num_ops_instances = get_number_of_op_types_per_instance(wd_revisions, kg_class.qid)\n",
    "        for op in ops:\n",
    "            op_counts = [d['count'] for d in num_ops_instances if d['_id']['op'] == op]\n",
    "            data['mean'].append(np.mean(op_counts))\n",
    "            data['max'].append(np.max(op_counts))\n",
    "            data['min'].append(np.min(op_counts))\n",
    "            data['std'].append(np.std(op_counts))\n",
    "            data['median'].append(np.median(op_counts))\n",
    "            data['class'].append(kg_class.name)\n",
    "            data['op'].append(op)\n",
    "\n",
    "descriptives_df = pd.DataFrame(data)\n",
    "save_df(descriptives_df, 'a_descriptives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7078bd-ce5c-4cc3-a476-d546895e83c7",
   "metadata": {},
   "source": [
    "Execute the following cell to load the precomputed dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2239d5-1121-432c-aa8f-7903284ecc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives_df = load_df('a_descriptives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a2bc2-501f-4005-9bea-38278219f46f",
   "metadata": {},
   "source": [
    "Now that the dataframe has been loaded, we will quickly check its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44a11c-4062-4d65-a0aa-51ad851998f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfce2f-7f3f-4b01-9018-3a818645fa90",
   "metadata": {},
   "source": [
    "### B. Number of documents\n",
    "In this section we will briefly explore the number of documents in our dataset. The following functions return respectively the total number of documents of a collection and the number of documents of a collection of a given class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50340ed9-fa79-45f7-a745-47d250884b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_count(collection):\n",
    "    return collection.estimated_document_count()\n",
    "\n",
    "def get_num_instances_of_class(collection, class_id):\n",
    "    return collection.count_documents({\"class_ids\": class_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeda5c2-9c4c-4687-a350-d8b5effe9090",
   "metadata": {},
   "source": [
    "We can now execute the functions to check the number of entities and revisions in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8125fd-cf75-4815-b24d-034ef8556933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of entities: {get_doc_count(wd_entities)}\")\n",
    "print(f\"Number of revisions: {get_doc_count(wd_revisions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769c320-cb86-4412-a7b9-43b4d2f1db49",
   "metadata": {},
   "source": [
    "In the following cell we are going to fetch the number of instances of each class indexed in our database, so we can compare them to the total number of instances of that class.\n",
    "\n",
    "> This cell should execute quickly (<1min), but we also provide the precomputed dataset in the following cell in case it's necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7667c-b19b-456a-9fac-d8bf7cb4270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'class': [],\n",
    "    'num_instances': [],\n",
    "    'indexed_instances': []\n",
    "}\n",
    "\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        indexed_class_instances = get_num_instances_of_class(wd_entities, kg_class.qid)\n",
    "        data['class'].append(kg_class.name)\n",
    "        data['num_instances'].append(len(kg_class.instances))\n",
    "        data['indexed_instances'].append(indexed_class_instances)\n",
    "\n",
    "num_instances_df = pd.DataFrame(data)\n",
    "save_df(num_instances_df, 'b_instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364b920-4f15-4a8a-9755-776b87631d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances_df = load_df('b_instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b3726-881a-4ce4-bc0a-d40a8f44e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(num_instances_df.sort_values(by='num_instances', ascending=False).head(n=10).to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a680c-6ba1-49f2-b6ec-3960678e12d3",
   "metadata": {},
   "source": [
    "If we see the table above we can check that we are just missing 1 or 2 instances for each class. These missing values could be missing from the diffs dataset from Wikidata, or could correspond to the 2 entities that couldn't be indexed in Mongo due to their size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d41a0-4394-45c8-86c7-8af233879188",
   "metadata": {},
   "source": [
    "### C: Number of edits per class\n",
    "In this section we will try to fetch the number of operations of each class and determine if there is a correlation between their number of operations and their importance (classrank score).\n",
    "\n",
    "The following cell returns the aggregated number of operations of the given type in a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4ad81-4788-4ec0-9942-4b6fb9f5de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_operations(collection, class_id, op_type=None):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"class_ids\": class_id}}\n",
    "    ]\n",
    "    \n",
    "    if op_type is not None and op_type in [\"add\", \"replace\", \"remove\"]:\n",
    "        pipeline.append({\"$match\": {\"$op\": op_type}})\n",
    "    \n",
    "    pipeline.append({\"$unwind\": \"$entity_diff\"})\n",
    "    \n",
    "    pipeline.append({\n",
    "            \"$group\":\n",
    "            {\n",
    "                \"_id\": \"$entity_diff.op\",\n",
    "                \"count\": {\"$sum\" : 1}\n",
    "            }\n",
    "    })\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09c106-46b6-4e58-bdfe-c8e62806e0ab",
   "metadata": {},
   "source": [
    "In the following cell we execute the previous function accross all the classes of our dataset. For each class we calculate the average number of operations by dividing the total operation count by the number of instances of the class.\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 1.5h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30dba2-a04f-4bdb-8c08-52ecb435b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'class': [],\n",
    "    'add': [],\n",
    "    'remove': [],\n",
    "    'replace': [],\n",
    "    'classrank': []\n",
    "}\n",
    "\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        num_class_ops = get_number_of_operations(wd_revisions, kg_class.qid)\n",
    "        data['class'].append(kg_class.name)\n",
    "        data['classrank'].append(kg_class.classrank_score)\n",
    "        for op in num_class_ops:\n",
    "            data[op['_id']].append(op['count'] / len(kg_class.instances))\n",
    "\n",
    "class_ops_df = pd.DataFrame(data)\n",
    "class_ops_df['total'] = class_ops_df['add'] + class_ops_df['remove'] + class_ops_df['replace']\n",
    "class_ops_df.sort_values(by='total', ascending=True, inplace=True)\n",
    "\n",
    "save_df(class_ops_df, 'c_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c345a-eff0-4cbe-8799-9341b9ce908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ops_df = load_df('c_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c7880-cb60-4278-94ff-09fa72ddd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ops_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4e2b6-95b9-457a-9859-633af59cd099",
   "metadata": {},
   "source": [
    "We can see from the table above the results for 10 of the classes, but in order to better visualize the dataset we are going to create some charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1d545-e4c0-4766-b079-cb2c58fc9ac3",
   "metadata": {},
   "source": [
    "##### C.1. Number of operations per class\n",
    "The following function defines the base skeleton to plot a stacked bar chart with Plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da78c7-dfd6-4e50-a261-f6aa1e018dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_bar_chart(x_values, y, x_names, x_title, y_title, width=1000, height=1700):\n",
    "    fig = go.Figure()\n",
    "    for x_v, x_n in zip(x_values, x_names):\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=y,\n",
    "            x=x_v,\n",
    "            name=x_n,\n",
    "            orientation='h',\n",
    "            hovertemplate='%{x:.2f}',\n",
    "            texttemplate=\"%{x:.2f}\"\n",
    "        ))\n",
    "    \n",
    "    \"\"\"\n",
    "    totals = np.sum(x_values, axis=0)\n",
    "    for total, class_name in zip(totals, y):\n",
    "        fig.add_annotation(x=total, y=class_name,\n",
    "                           text=f\"<b>{str(round(total, 1))}<b>\",\n",
    "                           showarrow=False,\n",
    "                           xshift=25,\n",
    "                           font=dict(size=15, family=\"Serif\"))\n",
    "    \"\"\"\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        xaxis_title=x_title,\n",
    "        yaxis_title=y_title,\n",
    "        legend_title=\"Operation type\",\n",
    "        height=height,\n",
    "        width=width,\n",
    "        font_family=\"Serif\", font_size=24,\n",
    "        uniformtext_minsize=14\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add66cef-4720-4c74-8947-cbb62bb4a99b",
   "metadata": {},
   "source": [
    "We are going to use the previous function to plot the average number of operations of each class. Each stack in the bar will correspond to the operation type (addition, removal or replacement):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5225ea-ee2f-4733-8ea6-a9396232f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = stacked_bar_chart([class_ops_df['add'], class_ops_df['remove'], class_ops_df['replace']], class_ops_df['class'],\n",
    "                        ['Additions', 'Removals', 'Replacements'], \"Average operations per instance\", \"Class\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11c168-cf98-454b-b9bb-51b45925c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'c_1_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eecb9f-d40d-45c1-9fc9-9fe57b0fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cecfc-3569-4a08-be6c-3b101f38470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_class_ops_df = class_ops_df.sort_values(by=['total'], ascending=False).head(n=10).sort_values(by=['total'])\n",
    "fig = stacked_bar_chart([sort_class_ops_df['add'], sort_class_ops_df['remove'], sort_class_ops_df['replace']], sort_class_ops_df['class'],\n",
    "                        ['Additions', 'Removals', 'Replacements'], \"Average operations per instance\", \"Class\", height=650, width=1500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1b46d-31c8-431d-9de2-e4d72dcd9d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_fig(fig, 'c_1_ops_paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0499f-8885-49d6-aae7-9d4fe4e71a1a",
   "metadata": {},
   "source": [
    "##### C.2. Correlation between operations in a class and classrank score\n",
    "In this section we are going to explore a possible correlation between the number of operations of a class and its importance (classrank score). We will begin by plotting number of removal operations of each class and its classrank score, with a regression line calculated using OLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a8ac0-d4b5-454f-aa56-1321d67188e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(class_ops_df, x=\"remove\", y=\"classrank\", trendline=\"ols\", hover_name=\"class\",\n",
    "                 labels={'remove': \"Average removals per instance\", 'classrank': \"Classrank score\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca58105-178c-4b13-937d-3d1ffcb0b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'c2_corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc45444-fff9-4b70-b8d4-39f3be893661",
   "metadata": {},
   "source": [
    "We will now check if the same trend is followed with the number of addition operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86dcd47-e027-447a-aa0f-2d2f2b4158a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(class_ops_df, x=\"add\", y=\"classrank\", trendline=\"ols\", hover_name=\"class\",\n",
    "                 labels={'add': \"Average additions per instance\", 'classrank': \"Classrank score\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a03de-a1ee-4b7a-9adb-cc1120654cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'c3_corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d33128-4860-49c8-9bef-1d3acff79847",
   "metadata": {},
   "source": [
    "To finish this section we are going to calculate the pearson correlation between each variable to check if there is a correlation between the number of operations and the importance of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3e680-8d98-429d-b307-91dd37727705",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = class_ops_df.corr(method='pearson')\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2f207-0c51-4f77-bee5-28c09c08de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.tril(np.ones_like(corr_df, dtype=bool))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=corr_df.mask(mask),\n",
    "    x=corr_df.columns,\n",
    "    y=corr_df.columns,\n",
    "    colorscale=px.colors.diverging.RdBu,\n",
    "    zmin=-1,\n",
    "    zmax=1,\n",
    "    texttemplate=\"%{z:.2f}\")\n",
    ")\n",
    "fig.update_layout(width=1000, height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7279e0-a9c0-4590-98b0-4bfab1a5acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'c3_corr_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c475c6-38a3-4054-89d1-db4b5981af32",
   "metadata": {},
   "source": [
    "### D: Count of properties per class\n",
    "In this section we are going to check which properties are more common on each class. To do so, we are going to define the following query that aggregates the claims of each entity from a given class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48631b-4ee5-45b7-9ebd-60a5da245b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties_count(collection, class_id):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"class_ids\": class_id, \"entity_json.claims\": { \"$exists\": \"true\", \"$not\": {\"$size\": 0} }}},\n",
    "        {\"$project\": {\"claims\": {\"$objectToArray\": \"$entity_json.claims\"}}},\n",
    "        {\"$unwind\": \"$claims\"},\n",
    "        {\n",
    "            \"$group\":\n",
    "            {\n",
    "                \"_id\": \"$claims.k\", \n",
    "                \"count\": {\"$sum\" : 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4bef0-910b-4ad3-a3fd-705d9ea888a7",
   "metadata": {},
   "source": [
    "In the following cell we execute the query for every class.\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 2.5h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cf294-598f-444b-a7c8-98800f944d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_props_data = {\n",
    "    'class': [],\n",
    "    'prop': [],\n",
    "    'count': []\n",
    "}\n",
    "\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        num_class_props = get_properties_count(wd_entities, kg_class.qid)\n",
    "        for prop in num_class_props:\n",
    "            classes_props_data['class'].append(kg_class.name)\n",
    "            classes_props_data['prop'].append(prop['_id'])\n",
    "            classes_props_data['count'].append(prop['count'] / len(kg_class.instances))\n",
    "    \n",
    "classes_props_df = pd.DataFrame(classes_props_data)\n",
    "save_df(classes_props_df, 'd_prop_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad805a6b-117b-406c-98af-6ad081289174",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_props_df = load_df('d_prop_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a752c2-8154-4733-81eb-58c2168ccaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_props_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45360af-15de-4c2a-9efc-6dc5fd6bf7ea",
   "metadata": {},
   "source": [
    "In the table above we can see the distribution of some properties of the human class.\n",
    "\n",
    "In order to visualize this better we are going to plot the most common properties of every class. The following cell defines a function that plots a bar chart with a dropdown to select the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37b969-ed33-4182-af11-51992acba4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropdown_bar_chart(x_data, y_data, labels, fig_title, x_axis_title, y_axis_title, bar_color=px.colors.qualitative.Plotly[0],\n",
    "                            hovertemplate='%{x:.2f}', hovername='Count', x_range=None):\n",
    "    fig = go.Figure()\n",
    "    buttons = []\n",
    "    i = 0\n",
    "    for x, y, label in zip(x_data, y_data, labels):\n",
    "        visible = i == 0 # only show first trace at start\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=y,\n",
    "            x=x,\n",
    "            name=hovername,\n",
    "            orientation='h',\n",
    "            visible=visible,\n",
    "            hovertemplate=hovertemplate,\n",
    "            marker_color=bar_color\n",
    "        ))\n",
    "\n",
    "        visible_arr = [False] * len(x_data)\n",
    "        visible_arr[i] = True\n",
    "        i += 1\n",
    "        buttons.append(dict(label=label,\n",
    "                            method=\"update\",\n",
    "                            args=[{\"visible\": visible_arr},\n",
    "                                  {\"title\": f\"{fig_title}: {label}\",\n",
    "                                   \"annotations\": []}]))\n",
    "    fig.update_layout(updatemenus=[dict(active=0, buttons=buttons, y=1.07)], title_text=f\"{fig_title}: {labels[0]}\", \n",
    "        xaxis_title=x_axis_title,\n",
    "        yaxis_title=y_axis_title,\n",
    "                     height=700)\n",
    "    if x_range is not None:\n",
    "        fig.update_xaxes(range=x_range)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da3e197-0a93-46f8-ba93-52ee178ea679",
   "metadata": {},
   "source": [
    "In the following cell we plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96991018-231a-4803-94cb-d89f5f3ff470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes_prop_count(df, num_props):\n",
    "    class_labels = df['class'].unique()\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for label in class_labels:\n",
    "        top_props_dict = {row['prop']: row['count'] for _, row\n",
    "                          in sorted(df[df['class'] == label].iterrows(), key=lambda row: row[1]['count'], reverse=True)[:num_props]\n",
    "                          if row['prop'] != 'P31'}\n",
    "        props = get_name_of_props(list(top_props_dict.keys()))\n",
    "        count = [v * 100 for v in top_props_dict.values()]\n",
    "        \n",
    "        y_data.append(props[::-1])\n",
    "        x_data.append(count[::-1])\n",
    "    return plot_dropdown_bar_chart(x_data, y_data, class_labels, \"Top properties in instances of class\",\n",
    "                                   \"Appearance percentage in class\", \"Property\", hovertemplate=\"%{x:.2f}%\",\n",
    "                                   hovername=\"Appearance\", x_range=[0, 100])\n",
    "    \n",
    "\n",
    "fig = plot_classes_prop_count(classes_props_df, 25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01a33d-5d57-44e9-ba12-390023f6a96b",
   "metadata": {},
   "source": [
    "In the figure above we can inspect the most common properties from every class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d69cf6-b4cf-4c5a-9e75-cf11a2cd6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'd_prop_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5d227-67c5-4904-9c81-3fc6a3c00008",
   "metadata": {},
   "source": [
    "### E: Properties most removed/replaced globally\n",
    "In this section we are going to explore which properties are more usually edited in each class.\n",
    "\n",
    "We will first define a set of regular expressions that can be used to match edits that modify specific parts of an entity:\n",
    "- **PURE_PROPERTY_EDIT_REGEX**: This matches modifications to a complete statement group (i.e. removing all the statements of a property or adding a property for the first time).\n",
    "- **PROPERTY_STATEMENTS_EDIT_REGEX**: This matches any modification to a property, but not its references or qualifiers.\n",
    "- **PROPERTY_REFERENCES_EDIT_REGEX**: This matches any modification to the references of a property.\n",
    "- **PROPERTY_QUALIFIERS_EDIT_REGEX**: This matches any modification to the qualifiers of a property.\n",
    "- **PROPERTY_ANY_EDIT_REGEX**: This matches any type of modification to a property, including references and qualifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5204a3-cf0f-448f-af01-9720cd3c2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "PURE_PROPERTY_EDIT_REGEX = \"\\/claims\\/P([0-9]*)$\"\n",
    "PROPERTY_STATEMENTS_EDIT_REGEX = \"^(?!.*(\\/hash|[0-9]\\/id|\\/references|\\/qualifiers))\\/claims\\/P([0-9]*).*$\"\n",
    "PROPERTY_REFERENCES_EDIT_REGEX = \"^(?!.*(\\/hash|[0-9]\\/id))\\/claims\\/P([0-9]*)\\/[0-9]*\\/references.*$\"\n",
    "PROPERTY_QUALIFIERS_EDIT_REGEX = \"^(?!.*(\\/hash|[0-9]\\/id))\\/claims\\/P([0-9]*)\\/[0-9]*\\/qualifiers.*$\"\n",
    "PROPERTY_ANY_EDIT_REGEX = \"^(?!.*(\\/hash|[0-9]\\/id))\\/claims(\\/P([0-9]*))?.*$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7cf7e-8d4b-4d67-85f7-d8bb89f1b3eb",
   "metadata": {},
   "source": [
    "The following functions will query the database to get the number of editions that match a given regular expression from above for each property both in a given class and also globally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6e5fe-17ae-48bd-9ddd-0e3c83dcb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties_edited(collection, class_id, path_regex):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"class_ids\": class_id}},\n",
    "        {\"$unwind\": \"$entity_diff\"},\n",
    "        {\"$match\": {\"entity_diff.path\": {\"$regex\": path_regex}}},\n",
    "        {\"$addFields\": {\"prop\": {\"$regexFind\": {\"input\": \"$entity_diff.path\", \"regex\": \"P([0-9]*)\"}}}},\n",
    "        {\n",
    "            \"$group\": \n",
    "            {\n",
    "                \"_id\": {\"prop\": \"$prop.match\", \"op\": \"$entity_diff.op\"},\n",
    "                \"count\": {\"$sum\" : 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))\n",
    "\n",
    "def get_properties_edited_total(collection, path_regex):\n",
    "    pipeline = [\n",
    "        {\"$unwind\": \"$entity_diff\"},\n",
    "        {\"$match\": {\"path\": {\"$regex\": path_regex}}},\n",
    "        {\"$addFields\": {\"prop\": {\"$regexFind\": {\"input\": \"$path\", \"regex\": \"P([0-9]*)\"}}}},\n",
    "        {\n",
    "            \"$group\": \n",
    "            {\n",
    "                \"_id\": {\"prop\": \"$prop.match\", \"op\": \"$op\"},\n",
    "                \"count\": {\"$sum\" : 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264e9c7-9d13-48af-9823-5e80b9d5ce12",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### E.1. Number of operations to a statement\n",
    "We will start by getting the number of operations of each property for every class. As we have done previously, this count is averaged between all the instances of each class:\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 5h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9868c-1cb3-4656-90f1-7cafe8aa6c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_claims_ops = {\n",
    "    'class': [],\n",
    "    'prop': [],\n",
    "    'op': [],\n",
    "    'count': []\n",
    "}\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        num_class_props = get_properties_edited(wd_revisions, kg_class.qid, path_regex=PROPERTY_STATEMENTS_EDIT_REGEX)\n",
    "        for prop in num_class_props:\n",
    "            classes_claims_ops['class'].append(kg_class.name)\n",
    "            classes_claims_ops['prop'].append(prop['_id']['prop'])\n",
    "            classes_claims_ops['op'].append(prop['_id']['op'])\n",
    "            classes_claims_ops['count'].append(prop['count'] / len(kg_class.instances))\n",
    "\n",
    "classes_claims_ops_df = pd.DataFrame(classes_claims_ops)\n",
    "save_df(classes_claims_ops_df, 'e1_claims_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84923b-f715-4b7d-89c4-e8c00bcec3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_claims_ops_df = load_df('e1_claims_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286565e-8e62-41ef-a42b-f23c280ca115",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_claims_ops_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c5aca-22fc-46ef-a732-e9e9eb811101",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### E.2. Number of operations to a statement group\n",
    "In this case we are going to get the number of operations of each statement group for every class. A statement group may contain more than one statement, and only consists of addition and removal operations (when a new 'property' is added to an entity and when all the statements of a property are removed at once from an entity):\n",
    "\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 5h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1145a-1724-4fba-bcba-78631377ed12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_pure_prop_data = {\n",
    "    'class': [],\n",
    "    'prop': [],\n",
    "    'op': [],\n",
    "    'count': []\n",
    "}\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        num_class_ops = get_properties_edited(wd_revisions, kg_class.qid, path_regex=PURE_PROPERTY_EDIT_REGEX)\n",
    "        for prop in num_class_ops:\n",
    "            classes_pure_prop_data['class'].append(kg_class.name)\n",
    "            classes_pure_prop_data['prop'].append(prop['_id']['prop'])\n",
    "            classes_pure_prop_data['op'].append(prop['_id']['op'])\n",
    "            classes_pure_prop_data['count'].append(prop['count'] / len(kg_class.instances))\n",
    "\n",
    "classes_pure_prop_df = pd.DataFrame(classes_pure_prop_data)\n",
    "save_df(classes_pure_prop_df, 'e2_pure_prop_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ada6f7-957e-412f-ab3f-5b52c4aa0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_pure_prop_df = load_df('e2_pure_prop_ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd40de6-440a-400c-b22c-e247fcf4f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_pure_prop_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0a181-6ff1-4d69-b16f-5011b0a4362a",
   "metadata": {},
   "source": [
    "In the following cell we are going to plot the most created statement groups for each class. This may not be the same as the most common properties in a class, since many of these statement groups could be deleted in the final state of the entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495a76d-a5bc-462e-b020-0ad2386e9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_created_properties(df, num_props):\n",
    "    class_labels = df['class'].unique()\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for label in class_labels:\n",
    "        top_props_dict = {row['prop']: row['count'] for _, row\n",
    "                          in sorted(df[(df['class'] == label) & (df['op'] == 'add')].iterrows(), key=lambda row: row[1]['count'], reverse=True)[:num_props]\n",
    "                          if row['prop'] != 'P31'}\n",
    "        props = get_name_of_props(list(top_props_dict.keys()))\n",
    "        count = [v for v in top_props_dict.values()]\n",
    "        \n",
    "        y_data.append(props[::-1])\n",
    "        x_data.append(count[::-1])\n",
    "    return plot_dropdown_bar_chart(x_data, y_data, class_labels, \"Most created properties of class\",\n",
    "                                   \"Average creations per instance\", \"Property\")\n",
    "    \n",
    "\n",
    "fig = plot_most_created_properties(classes_pure_prop_df, 25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421e9b4-ce1d-46b1-8e18-67acfbcf98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'e2_pure_prop_created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf7e69-c07c-47d8-ab7f-eafa0d763667",
   "metadata": {},
   "source": [
    "Now, we are going to see which are the most deleted properties for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9f64e-373d-4d1d-bf90-4491ad1a7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_deleted_properties(df, num_props):\n",
    "    class_labels = df['class'].unique()\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for label in class_labels:\n",
    "        top_props_dict = {row['prop']: row['count'] for _, row\n",
    "                          in sorted(df[(df['class'] == label) & (df['op'] == 'remove')].iterrows(), key=lambda row: row[1]['count'], reverse=True)[:num_props]\n",
    "                          if row['prop'] != 'P31'}\n",
    "        props = get_name_of_props(list(top_props_dict.keys()))\n",
    "        count = [v for v in top_props_dict.values()]\n",
    "        \n",
    "        y_data.append(props[::-1])\n",
    "        x_data.append(count[::-1])\n",
    "    return plot_dropdown_bar_chart(x_data, y_data, class_labels, \"Most deleted properties of class\",\n",
    "                                   \"Average deletions per instance\", \"Property\", bar_color=op_colors['remove'])\n",
    "    \n",
    "\n",
    "fig = plot_most_deleted_properties(classes_pure_prop_df, 25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774afa5-ae04-49d4-9da5-daa3a3db9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'e2_pure_prop_deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf324b-9cf7-45e8-9439-dfe017ef0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(df, x, y, x_title, y_title, hovername='Count', width=950, height=1100,\n",
    "                   bar_color=px.colors.qualitative.Plotly[0], max_range=None, texttemplate='%{x:.2f}'):\n",
    "    y = get_name_of_props(df[y])[::-1]\n",
    "    y = [el if len(el) <= 26 else f\"{el[:23]}...\" for el in y]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=y,\n",
    "        x=list(df[x])[::-1],\n",
    "        orientation='h',\n",
    "        hovertemplate='%{x}',\n",
    "        texttemplate=texttemplate,\n",
    "        textposition='outside',\n",
    "        name=hovername,\n",
    "        marker_color=bar_color\n",
    "    ))\n",
    "    \n",
    "    if max_range is None:\n",
    "        max_range = max(df[x]) * 1.15\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=x_title,\n",
    "        yaxis_title=y_title,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        font_family=\"Serif\", font_size=23,\n",
    "        margin=dict(l=275),\n",
    "        uniformtext_minsize=20,\n",
    "        xaxis=dict(range=[0, max_range], tickformat='digits')\n",
    "    )\n",
    "    fig.update_yaxes(automargin=False)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771c8d0-9b8e-4011-b4f2-b572ce2c6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_deleted_props_of_class(df, class_name, num_props=10, height=650, width=1000):\n",
    "    class_deletions_df = classes_pure_prop_df[(classes_pure_prop_df['class'] == class_name) & (classes_pure_prop_df['op'] == 'remove')].sort_values(by='count', ascending=False)\n",
    "    class_deletions_df = class_deletions_df.head(n=num_props)\n",
    "    return plot_bar_chart(class_deletions_df, 'count', 'prop', 'Average deletions per instance', 'Property',\n",
    "                          height=height, width=width, bar_color=px.colors.qualitative.Plotly[1], max_range=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0e4f2-f32b-44de-b130-7e5f4711d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_most_deleted_props_of_class(classes_pure_prop_df, 'human')\n",
    "fig.show()\n",
    "save_fig(fig, 'e2_pure_prop_deleted_human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7eb829-c322-449d-b4a2-0b05131e0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_most_deleted_props_of_class(classes_pure_prop_df, 'taxon')\n",
    "fig.show()\n",
    "save_fig(fig, 'e2_pure_prop_deleted_taxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da5666-c045-4d96-bfeb-663b378fa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_most_deleted_props_of_class(classes_pure_prop_df, 'sovereign state')\n",
    "fig.show()\n",
    "save_fig(fig, 'e2_pure_prop_deleted_sovereign_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95b12b-f0f4-466a-803f-8abca7cb1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_most_deleted_props_of_class(classes_pure_prop_df, 'big city')\n",
    "fig.show()\n",
    "save_fig(fig, 'e2_pure_prop_deleted_big_city')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b93c5-8c8d-49f4-9ef6-4445940a38ad",
   "metadata": {},
   "source": [
    "### F: Class operations per decile\n",
    "In this section we are going to explore the dynamics with respect to time of each modification. While we have focused previously on the most created/removed properties of each class, we will now take into account the timeframe of these modifications (e.g. which properties are more created in the first moments of an entity).\n",
    "\n",
    "To do so, we are going to define the following function that returns the modifications of an entity, grouped by the decile where they were produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e59a37-b6b3-4761-8820-b7d45d930899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties_edited_deciles(collection, entity_id, path_regex, decile_num=0):\n",
    "    if decile_num < 0 or decile_num > 9:\n",
    "        print(\"Decile must be a number between 0 and 9\")\n",
    "        return []\n",
    "    \n",
    "    pipeline = [\n",
    "        {\"$match\": {\"entity_id\": entity_id}},\n",
    "        {\"$sort\": {\"timestamp\": 1}},\n",
    "        {\"$bucketAuto\": {\n",
    "            \"groupBy\": \"$timestamp\",\n",
    "            \"buckets\": 10,\n",
    "            \"output\": {\n",
    "                \"diffs\" : {\"$push\": \"$entity_diff\" }\n",
    "            }\n",
    "        }},\n",
    "        {\"$group\": {\n",
    "          \"_id\": \"null\",\n",
    "              \"buckets\": {\n",
    "                \"$push\": \"$$ROOT\"\n",
    "              }\n",
    "            }\n",
    "        },\n",
    "        {\"$unwind\": {\"path\": \"$buckets\", \"includeArrayIndex\": \"bucketNum\"}},\n",
    "        {\"$unwind\": \"$buckets.diffs\"},\n",
    "        {\"$unwind\": \"$buckets.diffs\"},\n",
    "        {\"$match\": {\"buckets.diffs.path\": {\"$regex\": path_regex}}},\n",
    "        {\"$addFields\": {\"prop\": {\"$regexFind\": {\"input\": \"$buckets.diffs.path\", \"regex\": \"P([0-9]*)\"}}}},\n",
    "        {\n",
    "            \"$group\": \n",
    "            {\n",
    "                \"_id\": {\"prop\": \"$prop.match\", \"op\": \"$buckets.diffs.op\", \"bucket\": \"$bucketNum\"},\n",
    "                \"count\": {\"$sum\" : 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f2a55-0f93-4d0d-9909-4845d0a55143",
   "metadata": {},
   "source": [
    "In the following cell we are going to fetch this data for all the classes in our dataset.\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 10h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d23366-e56f-4ee2-8ab2-1e1a4af10eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pdb\n",
    "\n",
    "deciles_data = {\n",
    "    'decile': [],\n",
    "    'class': [],\n",
    "    'prop': [],\n",
    "    'op': [],\n",
    "    'count': []\n",
    "}\n",
    "\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        \n",
    "        deciles_classes_props = {i: defaultdict(int) for i in range(10)}\n",
    "        for instance in tqdm(kg_class.instances):\n",
    "            num_class_props_decile = get_properties_edited_deciles(wd_revisions, instance.qid,\n",
    "                                            path_regex=PROPERTY_STATEMENTS_EDIT_REGEX)\n",
    "\n",
    "            for res in num_class_props_decile:\n",
    "                key = (res['_id']['prop'], res['_id']['op'])\n",
    "                deciles_classes_props[res['_id']['bucket']][key] += res['count']\n",
    "\n",
    "        for decile in range(10):\n",
    "            if decile == 0:\n",
    "                continue\n",
    "            \n",
    "            for k, v in deciles_classes_props[decile - 1].items():\n",
    "                deciles_classes_props[decile][k] += v\n",
    "    \n",
    "                prop, op = k[0], k[1]\n",
    "                deciles_data['decile'].append(decile - 1)\n",
    "                deciles_data['class'].append(kg_class.name)\n",
    "                deciles_data['prop'].append(prop)\n",
    "                deciles_data['op'].append(op)\n",
    "                deciles_data['count'].append(v / len(kg_class.instances))\n",
    "            \n",
    "        for k, v in deciles_classes_props[9].items():\n",
    "            prop, op = k[0], k[1]\n",
    "            deciles_data['decile'].append(9)\n",
    "            deciles_data['class'].append(kg_class.name)\n",
    "            deciles_data['prop'].append(prop)\n",
    "            deciles_data['op'].append(op)\n",
    "            deciles_data['count'].append(v / len(kg_class.instances))\n",
    "\n",
    "deciles_prop_df = pd.DataFrame(deciles_data)\n",
    "save_df(deciles_prop_df, 'f_deciles_props_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef922c36-4088-425a-99d2-28471e01fa42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deciles_prop_df = load_df('f_deciles_props_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34613a-e2d2-4bae-8f15-96bc69b9a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles_prop_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a2805-bca0-477a-91e5-5b98ebedd0d3",
   "metadata": {},
   "source": [
    "In the following cell we are going to deploy a dashboard with all this data. This dashboard offers two endpoints: one to fetch the most edited properties of each class in a given decile, and the other to fetch this information globally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c09f6-781f-40ea-a1f7-7ff420eb1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash import callback, html, dcc\n",
    "import io\n",
    "\n",
    "n_props = 26\n",
    "\n",
    "app = JupyterDash(__name__, suppress_callback_exceptions=True)\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    html.Div(id='page-content')\n",
    "])\n",
    "\n",
    "\n",
    "index_page = html.Div([\n",
    "    dcc.Link('View global data', href='/global'),\n",
    "    html.Br(),\n",
    "    dcc.Link('View by decile', href='/deciles'),\n",
    "])\n",
    "\n",
    "classes = deciles_prop_df['class'].unique()\n",
    "\n",
    "page_1_layout = html.Div(\n",
    "    [\n",
    "        html.Div([\n",
    "            \"Class:\",\n",
    "            dcc.Dropdown(\n",
    "                id=\"kg_class\",\n",
    "                options=[{\"label\": c, \"value\": c} for c in classes],\n",
    "                value=classes[0],\n",
    "            )\n",
    "        ]),\n",
    "        html.Div([\n",
    "            \"Operation:\",\n",
    "            dcc.Dropdown(\n",
    "                id=\"op\",\n",
    "                options=[{\"label\": op, \"value\": op} for op in op_types],\n",
    "                value=op_types[0],\n",
    "            )\n",
    "        ]),\n",
    "        dcc.Graph(id=\"graph1\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph1\", \"figure\"),\n",
    "    Input(\"kg_class\", \"value\"),\n",
    "    Input(\"op\", \"value\"),\n",
    ")\n",
    "def update_graph1(kg_class, op):\n",
    "    df = classes_claims_ops_df[classes_claims_ops_df['class'] == kg_class]\n",
    "\n",
    "    top_props_dict = {row['prop']: row['count'] for _, row\n",
    "                      in sorted(df[df['op'] == op].iterrows(), key=lambda row: row[1]['count'], reverse=True)[:n_props]\n",
    "                      if row['prop'] != 'P31'}\n",
    "    \n",
    "    return get_figure_of(top_props_dict, op, kg_class)\n",
    "\n",
    "page_2_layout = html.Div(\n",
    "    [\n",
    "        html.Div([\n",
    "            \"Class:\",\n",
    "            dcc.Dropdown(\n",
    "                id=\"kg_class\",\n",
    "                options=[{\"label\": c, \"value\": c} for c in classes],\n",
    "                value=classes[0],\n",
    "            )\n",
    "        ]),\n",
    "        html.Div([\n",
    "            \"Decile:\",\n",
    "            dcc.Dropdown(\n",
    "                id=\"decile\",\n",
    "                options=[{\"label\": i, \"value\": i} for i in range(1, 11)],\n",
    "                value=1,\n",
    "            )\n",
    "        ]),\n",
    "        html.Div([\n",
    "            \"Operation:\",\n",
    "            dcc.Dropdown(\n",
    "                id=\"op\",\n",
    "                options=[{\"label\": op, \"value\": op} for op in op_types],\n",
    "                value=op_types[0],\n",
    "            )\n",
    "        ]),\n",
    "        dcc.Graph(id=\"graph2\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph2\", \"figure\"),\n",
    "    Input(\"kg_class\", \"value\"),\n",
    "    Input(\"decile\", \"value\"),\n",
    "    Input(\"op\", \"value\"),\n",
    ")\n",
    "def update_graph2(kg_class, decile, op):\n",
    "    decile_idx = int(decile) - 1\n",
    "    df = deciles_prop_df[deciles_prop_df['decile'] == decile_idx]\n",
    "    top_props_dict = {row['prop']: row['count'] for _, row\n",
    "                      in sorted(df[(df['class'] == kg_class) & (df['op'] == op)].iterrows(), key=lambda row: row[1]['count'], reverse=True)[:n_props]\n",
    "                      if row['prop'] != 'P31'}\n",
    "    return get_figure_of(top_props_dict, op, kg_class, decile)\n",
    "\n",
    "def get_figure_of(props_dict, op, class_name, decile=None):\n",
    "    fig = go.Figure()\n",
    "    props = get_name_of_props(list(props_dict.keys()))[::-1]\n",
    "    count = [v for v in props_dict.values()][::-1]\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=props,\n",
    "        x=count,\n",
    "        name=f\"Statements ({op})\",\n",
    "        orientation='h',\n",
    "        hovertemplate='%{x:.2f}',\n",
    "        marker_color=op_colors[op]\n",
    "    ))\n",
    "    \n",
    "    title = f\"Most edited properties for class '{class_name}'\"\n",
    "    if decile is not None:\n",
    "        title += f\" in decile {decile}\"\n",
    "    fig.update_layout(title_text=title, \n",
    "        xaxis_title=\"Average number of editions per instance\",\n",
    "        yaxis_title=\"Property\",\n",
    "        height=1000)\n",
    "    return fig\n",
    "\n",
    "# Update the index\n",
    "@app.callback(Output('page-content', 'children'),\n",
    "         [Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/global':\n",
    "        return page_1_layout\n",
    "    elif pathname == '/deciles':\n",
    "        return page_2_layout\n",
    "    else:\n",
    "        return index_page\n",
    "\n",
    "app.run_server(mode=\"external\", host='0.0.0.0', port='8050')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd9ca5-eb61-4d8c-a117-b01507e68862",
   "metadata": {},
   "source": [
    "## G: Conflict and general measures\n",
    "In this last section we are going to fetch conflict measures and also general information of each class.\n",
    "\n",
    "We will start by defining a set of functions to fetch all the operations of the instances of a class or of a single entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bec994-615b-4492-abfb-b94851ef88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ops_of_class(collection, class_id, path_regex, match_prop=True):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"class_ids\": class_id}},\n",
    "        {\"$project\": {\"entity_diff\": 1, \"entity_id\": 1, \"id\": 1}},\n",
    "        {\"$unwind\": \"$entity_diff\"},\n",
    "        {\"$match\": {\"entity_diff.path\": {\"$regex\": path_regex}}}\n",
    "    ]\n",
    "\n",
    "    if match_prop:\n",
    "        pipeline.append({\"$addFields\": {\"prop\": {\"$regexFind\": {\"input\": \"$entity_diff.path\", \"regex\": \"P([0-9]*)\"}}}})\n",
    "        \n",
    "    return collection.aggregate(pipeline)\n",
    "\n",
    "def get_ops_of_entity(collection, entity_id, path_regex, match_prop=True):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"entity_id\": entity_id}},\n",
    "        {\"$project\": {\"entity_diff\": 1, \"entity_id\": 1, \"id\": 1}},\n",
    "        {\"$unwind\": \"$entity_diff\"},\n",
    "        {\"$match\": {\"entity_diff.path\": {\"$regex\": path_regex}}}\n",
    "    ]\n",
    "    \n",
    "    if match_prop:\n",
    "        pipeline.append({\"$addFields\": {\"prop\": {\"$regexFind\": {\"input\": \"$entity_diff.path\", \"regex\": \"P([0-9]*)\"}}}})\n",
    "\n",
    "    return list(collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad91de8-373a-43ca-a66f-8b42149e764f",
   "metadata": {},
   "source": [
    "### G.1. Fetching data\n",
    "Now we will define a set of functions to detect edit wars given a set of operations. An edit war is considered a set of operations that start with a given value for a property, this value then is removed or changed to a different value, and finally the property is given the same value that it had before.\n",
    "\n",
    "The following functions detect these edit patterns and return both the number of edit wars and the operations that compose each edit war:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597771f8-4655-49ad-8903-97896a049548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _process_edit_wars(ops, accumulator_fn):\n",
    "    changes_dict = defaultdict(list)\n",
    "    \n",
    "    for op in ops:\n",
    "        op_type = op['entity_diff']['op']\n",
    "        path = op['entity_diff']['path']\n",
    "        changes_dict[path].append((op_type, op['entity_diff']['value']))\n",
    "    \n",
    "    for path, changes in changes_dict.items():\n",
    "        adds = [c for c in changes if c[0] == 'add']\n",
    "        replacements = [c for c in changes if c[0] == 'replace']\n",
    "        ops = adds + replacements\n",
    "        \n",
    "        values = []\n",
    "        for op in ops:\n",
    "            try:\n",
    "                if isinstance(op[1], list):\n",
    "                    if op[1][0]['mainsnak']['snaktype'] in ['somevalue', 'novalue']:\n",
    "                        value = op[1][0]['mainsnak']['snaktype']\n",
    "                    else:\n",
    "                        value = op[1][0]['mainsnak']['datavalue']['value']\n",
    "                elif isinstance(op[1], dict):\n",
    "                    if 'mainsnak' not in op[1]:\n",
    "                        value = op[1]['value']\n",
    "                    elif op[1]['mainsnak']['snaktype'] in ['somevalue', 'novalue']:\n",
    "                        value = op[1]['mainsnak']['snaktype']\n",
    "                    else:\n",
    "                        value = op[1]['mainsnak']['datavalue']['value']\n",
    "                else:\n",
    "                    value = op[1]\n",
    "            except:\n",
    "                print(\"Error processing op value\")\n",
    "                continue\n",
    "\n",
    "            if value in values:\n",
    "                accumulator_fn(path, changes)\n",
    "                break\n",
    "            values.append(value)\n",
    "\n",
    "def count_edit_wars(ops):\n",
    "    num_conflicts = 0\n",
    "    def add_conflict():\n",
    "        nonlocal num_conflicts\n",
    "        num_conflicts += 1\n",
    "    _process_edit_wars(ops, lambda path, changes: add_conflict())\n",
    "    return num_conflicts\n",
    "\n",
    "\n",
    "def detect_edit_wars(ops):\n",
    "    conflicts_dict = {}\n",
    "    def update_conflicts_dict(path, changes):\n",
    "        nonlocal conflicts_dict\n",
    "        conflicts_dict[path] = changes\n",
    "    _process_edit_wars(ops, lambda path, changes: update_conflicts_dict(path, changes))\n",
    "    return conflicts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd169995-8d37-46f2-82eb-3c3dd2ee2bc0",
   "metadata": {},
   "source": [
    "Now we will build two separate dataframes. The first one will contain the following information about each entity:\n",
    "- ID of the entity.\n",
    "- ID of the class the entity belongs to.\n",
    "- Number of revisions.\n",
    "- Number of operations.\n",
    "- Number of 'addition' operations.\n",
    "- Number of 'replacement' operations.\n",
    "- Number of 'removal' operations.\n",
    "- Number of edit wars detected.\n",
    "- Number of statement groups added.\n",
    "- Number of statement groups removed.\n",
    "- Number of statements added.\n",
    "- Number of statements removed.\n",
    "- Number of changes in rank in one of its statements.\n",
    "- Percentage of properties which are considered 'stable' (less than 5 changes to the property).\n",
    "- Total number of properties.\n",
    "\n",
    "The second one will contain the same information, but in this case about each property. The only fields not included will be the count of stable props and number of props."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5713b-d551-4bdf-aa1a-c2674dd45cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_props = classes_props_df['prop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827eceed-80bb-4999-b058-bd20062a001e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "stgroups_pattern = re.compile(r\"\\/claims\\/P([0-9]*)$\")\n",
    "statements_pattern = re.compile(r\"\\/claims\\/P([0-9]*)\\/([0-9]*)$\")\n",
    "\n",
    "\n",
    "def extract_ops_statistics(ops):\n",
    "    stgroups_ops = [o for o in ops if stgroups_pattern.match(o['entity_diff']['path'])]\n",
    "    statement_ops = [o for o in ops if statements_pattern.match(o['entity_diff']['path'])]\n",
    "    num_edit_wars = count_edit_wars(ops)\n",
    "    \n",
    "    return {\n",
    "        'stgroups_added': len([o for o in stgroups_ops if o['entity_diff']['op'] == 'add']),\n",
    "        'stgroups_removed': len([o for o in stgroups_ops if o['entity_diff']['op'] == 'remove']),\n",
    "        'statements_added': len([o for o in statement_ops if o['entity_diff']['op'] == 'add']),\n",
    "        'statements_removed': len([o for o in statement_ops if o['entity_diff']['op'] == 'remove']),\n",
    "        'revisions': len({o['id'] for o in ops}),\n",
    "        'additions': len([o for o in ops if o['entity_diff']['op'] == 'add']),\n",
    "        'replacements': len([o for o in ops if o['entity_diff']['op'] == 'replace']),\n",
    "        'removals': len([o for o in ops if o['entity_diff']['op'] == 'remove']),\n",
    "        'ops': len(ops),\n",
    "        'edit_wars': num_edit_wars,\n",
    "        'rank_changes': len([o for o in ops if '/rank' in o['entity_diff']['path']])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ed0b0-80bb-45ac-a79d-58b78001c0a2",
   "metadata": {},
   "source": [
    "The following cell fetches all the information of both dataframes. Everything has been joined in one loop in order to optimize the execution of the code, losing some code readability in the process.\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 6h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32e0db-4188-4ab2-b166-de9037587b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_entities_data = {\n",
    "    'entity': [], 'class': [], 'revisions': [], 'ops': [], 'edit_wars': [], 'additions': [],\n",
    "    'removals': [], 'replacements': [], 'stgroups_added': [], 'stgroups_removed': [],\n",
    "    'statements_added': [], 'statements_removed': [], 'rank_changes': [],\n",
    "    'stable_props': [], 'all_props': []\n",
    "}\n",
    "\n",
    "revs_props_data = {\n",
    "    'prop': [], 'class': [], 'revisions': [], 'ops': [], 'edit_wars': [], 'additions': [],\n",
    "    'removals': [], 'replacements': [], 'statements_added': [], 'statements_removed': [],\n",
    "    'stgroups_added': [], 'stgroups_removed': [], 'rank_changes': []\n",
    "}\n",
    "\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        \n",
    "        class_props_data = {}\n",
    "        for entity in kg_class.instances:\n",
    "            entity_ops = get_ops_of_entity(wd_revisions, entity.qid, path_regex=PROPERTY_STATEMENTS_EDIT_REGEX)\n",
    "\n",
    "            if len(entity_ops) == 0:\n",
    "                continue            \n",
    "\n",
    "            revs_entities_data['entity'].append(entity.qid)\n",
    "            revs_entities_data['class'].append(kg_class.qid)\n",
    "            \n",
    "            entity_props_ops = defaultdict(list)\n",
    "            for op in entity_ops:\n",
    "                entity_props_ops[op['prop']['match']].append(op)\n",
    "            \n",
    "            ops_statistics = defaultdict(int)\n",
    "            for prop, ops in entity_props_ops.items():\n",
    "                prop_statistics = extract_ops_statistics(ops)\n",
    "                \n",
    "                if prop not in class_props_data:\n",
    "                    class_props_data[prop] = defaultdict(int)\n",
    "                \n",
    "                for k, v in prop_statistics.items():\n",
    "                    class_props_data[prop][k] += v\n",
    "                    ops_statistics[k] += v\n",
    "\n",
    "            ops_statistics['revisions'] = len({o['id'] for o in entity_ops})\n",
    "            for k, v in ops_statistics.items():\n",
    "                revs_entities_data[k].append(v)\n",
    "            \n",
    "            # props with less than 5 'modifications' (replacements+removals)\n",
    "            revs_entities_data['stable_props'].append(sum([1 for k, v in entity_props_ops.items()\n",
    "                                                           if len([o for o in v if o['entity_diff']['op'] in ['replace', 'remove']]) < 5])\n",
    "                                                      / len(entity_props_ops))\n",
    "            revs_entities_data['all_props'].append(len(entity_props_ops))\n",
    "            \n",
    "        for prop, data in class_props_data.items():\n",
    "            revs_props_data['class'].append(kg_class.name)\n",
    "            revs_props_data['prop'].append(prop)\n",
    "            for k, v in data.items():\n",
    "                revs_props_data[k].append(v)\n",
    "\n",
    "revs_entities_data_df = pd.DataFrame(revs_entities_data)\n",
    "save_df(revs_entities_data_df, 'g_revs_entities_data')\n",
    "\n",
    "revs_props_data_df = pd.DataFrame(revs_props_data)\n",
    "save_df(revs_props_data_df, 'g_revs_props_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3dd03-c2f7-4419-bbc7-caa9025ca4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_entities_data_df = load_df('g_revs_entities_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48eec1-b383-40ef-9df4-bf630bef88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_entities_data_df[revs_entities_data_df['entity'] == 'Q7961430']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa282ec7-db43-4cb0-8203-3c1c29db1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_props_data_df = load_df('g_revs_props_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50363c0-c4c9-4b15-b699-c27e24db113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_entities_data_df.head(n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f26d4-4168-471f-91a7-86a511d6af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_props_data_df.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e9a93-8df9-4e23-8427-2b3ce96955b2",
   "metadata": {},
   "source": [
    "We can see above the contents of both Dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2797cb-5495-43b5-bff9-f915908b44db",
   "metadata": {},
   "source": [
    "### G.2. Analyzing conflict measures\n",
    "#### Entities with the most conflictiveness\n",
    "We can now see which entities have a higher conflictiveness rate from the data we have fetched. Our entities dataframe has some repeated rows (entities which belong to more than one class), so we will begin by deleting those duplicates. After that, we will calculate the mean number of edit wars per revisions of each instance. Finally, we will add a column to each row indicating the percentile that entity belong to, considering its number of edit wars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cec4ef-c711-4991-8f01-d508bbe2d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_entities_data_df = revs_entities_data_df.drop_duplicates('entity')\n",
    "\n",
    "grouped_entities_data_df['mean_edit_wars'] = grouped_entities_data_df['edit_wars'] / grouped_entities_data_df['revisions']\n",
    "grouped_entities_data_df['percentile'] = grouped_entities_data_df['edit_wars'].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a1286-5795-4a6e-a249-5b7331a9a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(grouped_entities_data_df[grouped_entities_data_df['edit_wars'] < 200], x=\"edit_wars\", nbins=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd3c7a-07b9-47a4-a8d5-71f95d20f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ELEMENTS = 15\n",
    "\n",
    "print(\"Entities with the most amount of edit wars\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "entities_most_edit_wars = grouped_entities_data_df.sort_values('percentile', ascending=False).head(n=NUM_ELEMENTS)\n",
    "for row in entities_most_edit_wars.itertuples():\n",
    "    print(f\"{get_name_of_props([row[1]])[0]}: {row.edit_wars} edit wars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ef3d5-0cc5-4462-b442-4a3c0a92c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_bar_chart(entities_most_edit_wars, 'edit_wars', 'entity', \"Number of edit wars\", \"Entity\", hovername=\"Edit wars\",\n",
    "                     width=750, height=1000, texttemplate='%{x}')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78746304-6a15-4e15-93b5-b252210f19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(fig, 'g_most_edit_wars_entities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0e1c6-f310-423d-b346-65a8f7ff2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entities with the most relative amount of edit wars\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "entities_most_edit_wars = grouped_entities_data_df.sort_values('mean_edit_wars', ascending=False).head(n=NUM_ELEMENTS)\n",
    "for row in entities_most_edit_wars.itertuples():\n",
    "    print(f\"{get_name_of_props([row[1]])[0]}: {row.mean_edit_wars} edit wars per revision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da38a91-d81d-4e4c-a323-7829975b247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(grouped_entities_data_df, 'entities_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec2c5c-57a0-4472-aace-05e1ae6e9695",
   "metadata": {},
   "source": [
    "#### Properties with the most conflictiveness\n",
    "We are now going to follow the same procedure with our properties Dataframe. In this case, we need to aggregate the values of properties accross all the classes they appear in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753de80e-31ad-43a8-a511-4d036fdad136",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_revs_props_data_df = revs_props_data_df.groupby('prop', as_index=False).sum()\n",
    "\n",
    "grouped_revs_props_data_df['mean_edit_wars'] = grouped_revs_props_data_df['edit_wars'] / grouped_revs_props_data_df['revisions']\n",
    "grouped_revs_props_data_df['percentile'] = grouped_revs_props_data_df['mean_edit_wars'].rank(pct=True)\n",
    "\n",
    "grouped_revs_props_data_df.sort_values('percentile', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5941e4-0ab0-4779-93e9-0cd3bb431255",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Properties with the most amount of mean edit wars\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "props_most_edit_wars = grouped_revs_props_data_df[grouped_revs_props_data_df['additions'] > 100].sort_values('percentile', ascending=False).head(n=NUM_ELEMENTS)\n",
    "for row in props_most_edit_wars.itertuples():\n",
    "    print(f\"{get_name_of_props([row[1]])[0]}: {round(row.mean_edit_wars, 2)} mean edit wars per revision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b9e65-31e4-465b-b28f-f78ab90f51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_bar_chart(props_most_edit_wars, 'mean_edit_wars', 'prop', \"Number of edit wars per revision\", \"Property\", hovername=\"Edit wars\")\n",
    "save_fig(fig, 'g_most_mean_edit_wars_properties')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856ad7a-f3d8-4b49-a092-c19f55ab0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "props_most_edit_wars = grouped_revs_props_data_df.sort_values('edit_wars', ascending=False).head(n=NUM_ELEMENTS)\n",
    "\n",
    "fig = plot_bar_chart(props_most_edit_wars, 'edit_wars', 'prop', \"Number of edit wars\", \"Property\", texttemplate='%{x}')\n",
    "save_fig(fig, 'g_most_edit_wars_properties')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c57abc-d4e9-42c8-9d7c-6be7c1c1fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(grouped_revs_props_data_df, 'properties_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f54f9-bd7c-46ee-a850-aa1ec0e768c8",
   "metadata": {},
   "source": [
    "#### Classes with the most conflictiveness\n",
    "In the following cell we are going to create a dataframe of classes by grouping all the values from the entities dataframe of each class. We are going to add a new column where the number of instances of each class is stored. In this case, the relative number of edit wars is computed based on the number of instances (i.e. mean number of edit wars per instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b947a-b2bc-4097-a2ae-eef46b2662ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_classes_data_df = revs_entities_data_df.groupby('class', as_index=False).sum()\n",
    "\n",
    "grouped_classes_data_df['num_instances'] = grouped_classes_data_df.apply(lambda row: len([c for c in top_classes if c.qid == row['class']][0].instances), axis=1)\n",
    "grouped_classes_data_df['mean_edit_wars'] = grouped_classes_data_df['edit_wars'] / grouped_classes_data_df['num_instances']\n",
    "\n",
    "grouped_classes_data_df['percentile'] = grouped_classes_data_df['mean_edit_wars'].rank(pct=True)\n",
    "\n",
    "grouped_classes_data_df.sort_values('percentile', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671df330-9236-4aa3-b448-f1e2fe49d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes with the most amount of edit wars\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "classes_most_edit_wars = grouped_classes_data_df.sort_values('percentile', ascending=False).head(n=NUM_ELEMENTS)\n",
    "for row in classes_most_edit_wars.itertuples():\n",
    "    print(f\"{get_name_of_props([row[1]])[0]}: {round(row.mean_edit_wars, 2)} mean edit wars per instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed552c-4d7c-4885-ae93-e9d1f1f04b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_bar_chart(classes_most_edit_wars, 'mean_edit_wars', 'class', \"Mean number of edit wars per instance\", \"Class\", hovername=\"Edit wars\")\n",
    "save_fig(fig, 'g_most_edit_wars_classes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081501e-f70f-4319-90e8-91b2fbd1aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes with the least amount of edit wars\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "classes_least_edit_wars = grouped_classes_data_df.sort_values('percentile', ascending=True).head(n=NUM_ELEMENTS)\n",
    "for row in classes_least_edit_wars.itertuples():\n",
    "    print(f\"{get_name_of_props([row[1]])[0]}: {round(row.mean_edit_wars, 3)} mean edit wars per instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec56e48-17fa-49d2-b14d-4d2c9ae3c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(grouped_classes_data_df, 'classes_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213513f-0130-4996-966c-0364da4b8e33",
   "metadata": {},
   "source": [
    "### Correlation between variables\n",
    "Finally, we will calculate the correlation between the variables of our entities dataframe using the Pearson method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85f7f0-984d-4eb7-b0ef-b8e9f76e65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_revs_entities_data_df = revs_entities_data_df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69149008-9577-471c-9da8-8b1c67cebbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.tril(np.ones_like(corr_revs_entities_data_df, dtype=bool))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=corr_revs_entities_data_df.mask(mask),\n",
    "    x=corr_revs_entities_data_df.columns,\n",
    "    y=corr_revs_entities_data_df.columns,\n",
    "    colorscale=px.colors.diverging.RdBu,\n",
    "    zmin=-1,\n",
    "    zmax=1,\n",
    "    texttemplate=\"%{z:.2f}\")\n",
    ")\n",
    "fig.update_layout(width=1000, height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e095f6-9e17-4aaa-ab84-ced97a4b04d2",
   "metadata": {},
   "source": [
    "### H: Life cycle of an entity\n",
    "In the following cells we are going to plot which are the most frequent operations made to entities in our dataset, as well as the most common transitions between these operations.\n",
    "\n",
    "We will start by defining the code that categorizes each operation and computes the transition counts form one operation to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc27ca7-f62d-443b-a3ef-206e5d89ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "path_to_state = collections.OrderedDict({\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)$\"): \"statement group\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)$\"): \"statement\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/mainsnak((\\/datavalue)|(\\/snaktype)).*$\"): \"statement value\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/rank$\"): \"statement rank\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/references(\\/([0-9]*))?$\"): \"reference\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/references\\/([0-9]*)\\/snaks\\/P([0-9]*)(\\/([0-9]*))?$\"): \"reference snak\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/references\\/([0-9]*)\\/snaks-order\\/.*$\"): \"reference order\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/references\\/([0-9]*)\\/snaks\\/P([0-9]*)\\/([0-9]*)((\\/datavalue)|(\\/snaktype)).*$\"): \"reference value\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/qualifiers$\"): \"qualifier\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/qualifiers\\/(P[0-9]*)(\\/([0-9]*))?$\"): \"qualifier snak\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/qualifiers-order(\\/([0-9]*))?$\"): \"qualifier order\",\n",
    "    re.compile(r\"^\\/claims\\/P([0-9]*)\\/([0-9]*)\\/qualifiers\\/P([0-9]*)\\/([0-9]*)((\\/datavalue)|(\\/snaktype)).*$\"): \"qualifier value\",\n",
    "    re.compile(r\"^\\/claims$\"): \"entity\",\n",
    "})\n",
    "\n",
    "states = [(s, t) for s in list(path_to_state.values()) for t in ['add', 'replace', 'remove']]\n",
    "states_idx = {}\n",
    "for i, s in enumerate(states):\n",
    "    states_idx[s] = i\n",
    "\n",
    "def get_operation_state(op):\n",
    "    path_type = \"other\"\n",
    "    for k in path_to_state:\n",
    "        if k.match(op['path']):\n",
    "            path_type = path_to_state[k]\n",
    "            break\n",
    "    \n",
    "    op_type = op['op']\n",
    "    if '/snaktype' in op['path']:\n",
    "        op_type = 'remove' if op['value'] == 'novalue' else 'add'\n",
    "        \n",
    "    \n",
    "    res = (path_type, op_type)\n",
    "\n",
    "    if path_type == \"other\":\n",
    "        print(f\"Input path: {op['path']}\")\n",
    "        print(f\"Output type: {res}\")\n",
    "\n",
    "    return (path_type, op_type)\n",
    "\n",
    "\n",
    "def build_state_count(ops):\n",
    "    state_counts = np.zeros((len(states), len(states)))\n",
    "    prev_state = None\n",
    "    \n",
    "    for op in ops:\n",
    "        curr_state = states_idx[get_operation_state(op['entity_diff'])]\n",
    "        if prev_state is not None:\n",
    "            state_counts[prev_state, curr_state] += 1\n",
    "            \n",
    "        prev_state = curr_state\n",
    "    return state_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae0f5f-9da1-4bec-a1a2-7a33830d581b",
   "metadata": {},
   "source": [
    "In the following cell we query the database to fetch this information:\n",
    "\n",
    "> ⚠️⏰ This cell may take a long time of execute (est. 7h, can vary greatly based on disk speed), the precomputed result is available in the following cell and can be directly loaded without executing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea189e-776f-4c15-9908-8c2cb312909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "state_counts = np.zeros((len(states), len(states)))\n",
    "with tqdm(top_classes) as t:\n",
    "    for kg_class in t:\n",
    "        t.set_description(f\"Class: {kg_class.name}\")\n",
    "        for entity in tqdm(kg_class.instances[:3000000]):\n",
    "            entity_ops = get_ops_of_entity(wd_revisions, entity.qid, path_regex=PROPERTY_ANY_EDIT_REGEX, match_prop=False)\n",
    "            state_counts = np.add(state_counts, build_state_count(entity_ops))\n",
    "\n",
    "save_df(state_counts, 'h_state_count')\n",
    "state_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8fc97-851c-45cb-9697-1520a395e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts = load_df('h_state_count')\n",
    "state_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a6ade-c3b1-42af-bee0-93eda3fb2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [18, 20, 30, 32, 35]\n",
    "for el in remove_list:\n",
    "    state_name = {v: k for k, v in states_idx.items()}[el]\n",
    "    del states_idx[state_name]\n",
    "state_counts = np.delete(state_counts, remove_list, 0)\n",
    "state_counts = np.delete(state_counts, remove_list, 1)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for s in states:\n",
    "    if s in states_idx:\n",
    "        states_idx[s] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452cd67-3f7a-484c-be65-51aadaf48482",
   "metadata": {},
   "source": [
    "#### Graph visualization\n",
    "Finally, this cell uses the pyvis library to plot the state counts that were computed before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b0bf8-1ea6-408a-a1b2-23fb3e09a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "import math\n",
    "\n",
    "max_num = np.max(state_counts)\n",
    "min_num = np.min(state_counts[state_counts > 0])\n",
    "\n",
    "max_incoming = max(np.sum(state_counts, axis=0))\n",
    "min_incoming = min(np.sum(state_counts, axis=0))\n",
    "\n",
    "\n",
    "g = net.Network(notebook=True, directed=True, height='750px', width='750px')\n",
    "\n",
    "# add nodes\n",
    "for s, i in states_idx.items():\n",
    "    if s == ('entity', 'remove') or s == ('qualifier value', 'remove'):\n",
    "        # we are not recording entity removals, since they are not available in the revision history data\n",
    "        continue\n",
    "    \n",
    "    if sum(state_counts[i, :]) + sum(state_counts[:, i]) > 0:\n",
    "        if s == ('entity', 'add'):\n",
    "            color = \"#8b5cf6\"\n",
    "            label = \"Create entity\"\n",
    "        else:\n",
    "            color = \"#60a5fa\"\n",
    "            label = f\"Modify {s[0]}\" if 'order' in s[0] or 'rank' in s[0] else f\"{s[1].capitalize()} {s[0]}\"\n",
    "        incoming_count = sum(state_counts[:, i])\n",
    "        if s == ('entity', 'add'):\n",
    "            # add all entities that have been created to count\n",
    "            incoming_count += 9300000\n",
    "        theta = 10\n",
    "        node_scale = math.log(((min_incoming * theta - max_incoming) / (min_incoming - max_incoming)) + (((1-theta) * incoming_count)/ (min_incoming - max_incoming)), theta)\n",
    "\n",
    "        g.add_node(i, label=label, color=color, borderWidth=1.5, size=max(15, node_scale * 65))\n",
    "\n",
    "for s1, i1 in states_idx.items():\n",
    "    if s1 == ('entity', 'remove') or s1 == ('qualifier value', 'remove'):\n",
    "        continue\n",
    "    \n",
    "    all_edges_s1 = sum(state_counts[i1, :])    \n",
    "    for s2, i2 in states_idx.items():\n",
    "        weight = state_counts[i1, i2]\n",
    "\n",
    "        if weight <= 0:\n",
    "            continue\n",
    "        \n",
    "        rel_weight = weight / all_edges_s1\n",
    "        theta = 100\n",
    "        graph_weight = math.log(((min_num * theta - max_num) / (min_num - max_num)) + (((1-theta) * weight)/ (min_num - max_num)), theta)\n",
    "        \n",
    "        if rel_weight > 0.11:\n",
    "            g.add_edge(i1, i2, width=max(0.25, graph_weight * 4), title=graph_weight)\n",
    "\n",
    "for s1, i1 in states_idx.items():\n",
    "    if s1 == ('entity', 'add') or s1 == ('entity', 'remove') or s1 == ('qualifier value', 'remove'):\n",
    "        continue\n",
    "    \n",
    "    all_edges_s1 = sum(state_counts[:, i1])\n",
    "    for s2, i2 in states_idx.items():\n",
    "        weight = state_counts[i2, i1]\n",
    "        if weight <= 0:\n",
    "            continue\n",
    "        \n",
    "        rel_weight = weight / all_edges_s1\n",
    "        if rel_weight > 0.11:\n",
    "            theta = 100\n",
    "            graph_weight = math.log(((min_num * theta - max_num) / (min_num - max_num)) + (((1-theta) * weight)/ (min_num - max_num)), theta)\n",
    "            all_edges = g.get_edges()\n",
    "            has_edge = False\n",
    "            for e in all_edges:\n",
    "                if e['from'] == i2 and e['to'] == i1:\n",
    "                    has_edge = True\n",
    "            \n",
    "            if not has_edge:\n",
    "                g.add_edge(i2, i1, width=max(0.25, graph_weight * 4), title=graph_weight)\n",
    "\n",
    "g.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"nodes\": {\n",
    "    \"font\": {\n",
    "      \"face\": \"verdana\",\n",
    "      \"strokeWidth\": 3,\n",
    "      \"size\": 24\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\n",
    "      \"inherit\": true\n",
    "    },\n",
    "    \"font\": {\n",
    "      \"face\": \"verdana\"\n",
    "    },\n",
    "    \"smooth\": {\n",
    "      \"type\": \"continuous\",\n",
    "      \"forceDirection\": \"none\",\n",
    "      \"roundness\": 0.25\n",
    "    }\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -277,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.06\n",
    "    },\n",
    "    \"minVelocity\": 0.76,\n",
    "    \"solver\": \"forceAtlas2Based\"\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "g.show(os.path.join(OUTPUT_DIR, \"edit_states_graph.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
